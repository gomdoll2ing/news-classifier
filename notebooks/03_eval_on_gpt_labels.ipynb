# ============================================================================
# 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ============================================================================
print("="*80)
print("ğŸ”§ 1. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸")
print("="*80)
!pip install -q --upgrade transformers datasets accelerate scikit-learn polars pandas
print("âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\n")

import os
import sys
import torch
import numpy as np
import pandas as pd
from pathlib import Path
import pickle
import gc
from google.colab import drive
from tqdm.auto import tqdm

# Scikit-learn
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Hugging Face
from datasets import load_dataset, Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments
)

# TQDMì´ Pandasì™€ ì˜ ì‘ë™í•˜ë„ë¡ ì„¤ì •
tqdm.pandas()

# ============================================================================
# 2. Google Drive ë§ˆìš´íŠ¸ ë° í›ˆë ¨ëœ ëª¨ë¸/3ìš”ì†Œ ë¡œë“œ
# ============================================================================
print("\n" + "="*80)
print("ğŸ“ 2. Google Drive ë§ˆìš´íŠ¸ ë° í›ˆë ¨ëœ ëª¨ë¸/3ìš”ì†Œ ë¡œë“œ")
print("="*80)

drive.mount('/content/drive', force_remount=False)

# í›ˆë ¨ ì‹œ 11ë²ˆ ì„¹ì…˜ì—ì„œ ì €ì¥í–ˆë˜ ê²½ë¡œ
SAVE_BASE_PATH = Path("/content/drive/MyDrive/best_news_classifier")
if not SAVE_BASE_PATH.exists():
    raise FileNotFoundError(f"âŒ ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {SAVE_BASE_PATH}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

try:
    # 1) ë”¥ëŸ¬ë‹(DL) ëª¨ë¸ ë¡œë“œ
    print("... 1/5) ë”¥ëŸ¬ë‹(RoBERTa) ëª¨ë¸ ë¡œë“œ ì¤‘ ...")
    dl_model = AutoModelForSequenceClassification.from_pretrained(SAVE_BASE_PATH).to(device)
    print("âœ… DL ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # 2) í† í¬ë‚˜ì´ì € ë¡œë“œ
    print("... 2/5) í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘ ...")
    tokenizer = AutoTokenizer.from_pretrained(SAVE_BASE_PATH)
    print("âœ… í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")

    # 3) ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ (DL, LR ê³µí†µ ì‚¬ìš©)
    print("... 3/5) ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ ì¤‘ ...")
    with open(SAVE_BASE_PATH / "label_encoder.pkl", 'rb') as f:
        label_encoder = pickle.load(f)
    print(f"âœ… ë¼ë²¨ ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (í´ë˜ìŠ¤: {label_encoder.classes_})")

    # 4) ë¡œì§€ìŠ¤í‹± íšŒê·€(LR) ëª¨ë¸ ë¡œë“œ
    print("... 4/5) ë¡œì§€ìŠ¤í‹± íšŒê·€(LR) ëª¨ë¸ ë¡œë“œ ì¤‘ ...")
    with open(SAVE_BASE_PATH / "baseline_lr.pkl", 'rb') as f:
        lr_clf = pickle.load(f)
    print("âœ… LR ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # 5) TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ
    print("... 5/5) TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ ì¤‘ ...")
    with open(SAVE_BASE_PATH / "baseline_tfidf_vec.pkl", 'rb') as f:
        tfidf_vectorizer = pickle.load(f)
    print("âœ… TF-IDF ë²¡í„°ë¼ì´ì € ë¡œë“œ ì™„ë£Œ")

except FileNotFoundError as e:
    print(f"\nâŒ [ì˜¤ë¥˜] ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    print("ì´ì „ í•™ìŠµ(11ë²ˆ ì„¹ì…˜)ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€, ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)


# ============================================================================
# 3. [â˜…í‰ê°€ ì „ìš©â˜…] ChatGPTë¡œ ë¼ë²¨ë§ëœ ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ
# ============================================================================
print("\n" + "="*80)
print("ğŸš€ 3. ChatGPT ë¼ë²¨ë§ ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ")
print("="*80)

# âš ï¸âš ï¸âš ï¸ [ì‚¬ìš©ì ìˆ˜ì • í•„ìš”] âš ï¸âš ï¸âš ï¸
# ë¼ë²¨ë§ ì‘ì—…(500, 1000, 3000ê°œ...)ì„ í†µí•´ ìµœì¢… ì €ì¥ëœ parquet íŒŒì¼ ê²½ë¡œ
LABELED_DATA_PATH = SAVE_BASE_PATH / "chatgpt_1000_labels_1990_2019.parquet"
# (ë§Œì•½ 500ê°œ ë²„ì „ì„ ì“°ë ¤ë©´: "chatgpt_500_labels_1990_2019.parquet")
# (ë§Œì•½ 3000ê°œ ë²„ì „ì„ ì“°ë ¤ë©´: "chatgpt_3000_labels_1990_2019.parquet")

if not LABELED_DATA_PATH.exists():
     raise FileNotFoundError(f"âŒ ë¼ë²¨ë§ëœ ìƒ˜í”Œ íŒŒì¼({LABELED_DATA_PATH.name})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print(f"âœ… {LABELED_DATA_PATH.name} íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
sample_df = pd.read_parquet(LABELED_DATA_PATH)
print(f"âœ… ì´ {len(sample_df)}ê°œ ìƒ˜í”Œ ë¡œë“œ ì™„ë£Œ.")

# (API í˜¸ì¶œ, í•„í„°ë§, ìƒ˜í”Œ ì¶”ì¶œ, ì €ì¥ ë¡œì§ ëª¨ë‘ ì œê±°ë¨)


# ============================================================================
# 4. [â˜…í‰ê°€ ì „ìš©â˜…] LR / DL ëª¨ë¸ë¡œ ìƒ˜í”Œ ì¶”ë¡  ì‹¤í–‰
# ============================================================================
print("\n" + "="*80)
print(f"ğŸ”¥ 4. LR / DL ëª¨ë¸ë¡œ {len(sample_df)}ê°œ ìƒ˜í”Œ ì¶”ë¡  ì‹¤í–‰")
print("="*80)

# --- 4-1. ë¡œì§€ìŠ¤í‹± íšŒê·€(LR) ì¶”ë¡  ---
print("... 1/2) ë¡œì§€ìŠ¤í‹± íšŒê·€(LR) ì¶”ë¡  ì¤‘ ...")
# í›ˆë ¨(5-4)ê³¼ 100% ë™ì¼í•œ ì „ì²˜ë¦¬: [í—¤ë“œë¼ì¸ + " " + ë³¸ë¬¸][:1000]
X_text_lr = sample_df.apply(
    lambda row: f"{row['headline'] if row['headline'] else ''} {row['content'] if row['content'] else ''}"[:1000], 
    axis=1
)
X_tfidf_lr = tfidf_vectorizer.transform(X_text_lr)
lr_pred_indices = lr_clf.predict(X_tfidf_lr)
lr_pred_labels = label_encoder.inverse_transform(lr_pred_indices)
sample_df['lr_label'] = lr_pred_labels
print("âœ… LR ì¶”ë¡  ì™„ë£Œ")

# --- 4-2. ë”¥ëŸ¬ë‹(DL) ì¶”ë¡  ---
print("... 2/2) ë”¥ëŸ¬ë‹(RoBERTa) ì¶”ë¡  ì¤‘ ...")
sample_hf_dataset = Dataset.from_pandas(sample_df)

def preprocess_and_tokenize_inference(examples):
    h = [t if t else "" for t in examples['headline']]
    c = [t if t else "" for t in examples['content']]
    texts = [f"{hh} {cc}"[:1000] for hh, cc in zip(h, c)] 
    return tokenizer(texts, padding="max_length", truncation=True, max_length=512)

N_PROC = 4 # ìƒ˜í”Œ ìˆ˜ê°€ ì ìœ¼ë¯€ë¡œ 4ë¡œë„ ì¶©ë¶„
sample_ds_tokenized = sample_hf_dataset.map(preprocess_and_tokenize_inference, batched=True, num_proc=N_PROC, remove_columns=sample_hf_dataset.column_names)
sample_ds_tokenized.set_format("torch")

# L4 ë˜ëŠ” A100ì— ë§ëŠ” ì¶”ë¡  ì„¤ì •
training_args = TrainingArguments(
    output_dir="/content/temp_inference_output",
    per_device_eval_batch_size=96,  # L4(24GB) ë˜ëŠ” A100(80GB)ì—ì„œ ë„‰ë„‰í•œ ë°°ì¹˜
    fp16=True,
    dataloader_num_workers=4,
    report_to="none"
)
trainer = Trainer(model=dl_model, args=training_args)

dl_predictions_output = trainer.predict(sample_ds_tokenized)
dl_pred_indices = np.argmax(dl_predictions_output.predictions, axis=1)
dl_pred_labels = label_encoder.inverse_transform(dl_pred_indices)
sample_df['dl_label'] = dl_pred_labels
print("âœ… DL ì¶”ë¡  ì™„ë£Œ")


# ============================================================================
# 5. [â˜…í‰ê°€ ì „ìš©â˜…] ìµœì¢… ì„±ëŠ¥ ë¹„êµ
# ============================================================================
print("\n" + "="*80)
print(f"ğŸ“Š 5. ìµœì¢… ì„±ëŠ¥ ë¹„êµ ({len(sample_df)}ê°œ ìƒ˜í”Œ ê¸°ì¤€)")
print("="*80)

valid_samples = sample_df[
    (sample_df['chatgpt_label'] != "ë¶„ë¥˜ì‹¤íŒ¨") &
    (sample_df['chatgpt_label'] != "ë¶„ë¥˜ì˜¤ë¥˜")
].copy()

print(f"ì´ {len(sample_df)}ê°œ ìƒ˜í”Œ ì¤‘ {len(valid_samples)}ê°œì˜ ìœ íš¨í•œ ìƒ˜í”Œë¡œ ë¹„êµë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n")

if len(valid_samples) > 0:
    lr_accuracy = accuracy_score(
        valid_samples['chatgpt_label'], 
        valid_samples['lr_label']
    )
    dl_accuracy = accuracy_score(
        valid_samples['chatgpt_label'], 
        valid_samples['dl_label']
    )

    print(f"--- 1990-2019 ë°ì´í„° (GPT-4o-mini ê¸°ì¤€) ---")
    print(f"ğŸ¤– [ë¡œì§€ìŠ¤í‹± íšŒê·€] ì •í™•ë„: {lr_accuracy:.2%}")
    print(f"ğŸ”¥ [ë”¥ëŸ¬ë‹ RoBERTa] ì •í™•ë„: {dl_accuracy:.2%}")
else:
    print("âŒ ë¹„êµí•  ìœ íš¨í•œ ChatGPT ë¶„ë¥˜ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")

print("\nğŸ‰ ëª¨ë“  í‰ê°€ ì‘ì—… ì™„ë£Œ! ğŸ‰")
print("--- [ìµœì¢… ê²°ê³¼ ìƒ˜í”Œ] ---")
print(valid_samples[['headline', 'chatgpt_label', 'lr_label', 'dl_label']].head())

# (ìµœì¢… ê²°ê³¼ ì €ì¥ ë¡œì§ì€ ì´ë¯¸ ë¼ë²¨ë§ ìŠ¤í¬ë¦½íŠ¸ì— ìˆìœ¼ë¯€ë¡œ, ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ê±°ë‚˜ ë®ì–´ì“°ê¸°)
FINAL_COMPARISON_PATH = SAVE_BASE_PATH / f"final_{len(sample_df)}_comparison_result.parquet"
valid_samples.to_parquet(FINAL_COMPARISON_PATH, index=False)
print(f"\nğŸ’¾ ìµœì¢… ë¹„êµ ê²°ê³¼ê°€ {FINAL_COMPARISON_PATH.name} ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
